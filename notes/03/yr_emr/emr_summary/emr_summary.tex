\documentclass{article}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{parskip}
\usepackage{multicol}
\usepackage{xcolor}
\usepackage{fancyhdr}
\usepackage{physics}
\usepackage{graphicx} % Required for inserting images
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{mathtools}

% commands
\newcommand{\deq}{\vcentcolon=}
\newcommand{\idd}{\text{Ä‘}}
\newcommand{\nimplies}{\centernot\implies}
\newcommand{\vc}[1]{\boldsymbol{#1}}

% margin settings
\geometry{
    a4paper,
    left=7mm,
    right=7mm,
    top=2cm,
    bottom=7mm
}

% proof environments
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem*{remark}{Remark} % unnumbered remarks

% header and footer
\pagestyle{fancy}
\fancyfoot{} % removes footer
\fancyhf{}
\renewcommand{\headrulewidth}{0.5pt}
\fancyhead[L]{Electromagnetism and relativity}
\fancyhead[R]{\thepage}

\begin{document}

\begin{multicols*}{3}
% starred environment ensures text remains in same column
\noindent

\subsubsection*{Vector products}
$$\boldsymbol{a}\cdot\boldsymbol{b}=ab\cos\theta$$
$$\boldsymbol{a}\times
\boldsymbol{b}=ab\sin\theta\hat{\boldsymbol{n}}$$
$$\boldsymbol{a}\times\boldsymbol{b}
=-\boldsymbol{b}\times\boldsymbol{a}$$
$$\boldsymbol{a}\times(\boldsymbol{b}\times\boldsymbol{c})
=\boldsymbol{b}(\boldsymbol{a}\cdot\boldsymbol{c})
-\boldsymbol{c}(\boldsymbol{a}\cdot\boldsymbol{b})$$

\subsubsection*{Suffix notation}
\begin{enumerate}
    \item A suffix that appears \underline{twice}
    implies a summation.
    \item Any suffix \underline{cannot appear} \\ 
    \textbf{more than twice} in any term.
\end{enumerate}
We define the \textbf{Kronecker delta} as:
$$\delta_{ij}=\left\{\begin{array}{ll}
    1 & i=j \\
    0 & i\neq j
\end{array}\right.$$
and the \textbf{Levi-Civita} as:
$$\epsilon_{ijk}=\left\{
\begin{array}{lll}
    +1 & 123,312,231 \\
    -1 & 132,213,321 \\
    0 & \text{repeat indices.}
\end{array}\right.$$
Consequently:
\begin{align*}
    &\epsilon_{ijk}=\epsilon_{kij}=\epsilon_{jki} \\
    &=-\epsilon_{ijk}=-\epsilon_{ijk}=-\epsilon_{ijk}
\end{align*}
and we have the following identities:
$$\boldsymbol{a}
=\sum_{i=1}^{3}a_i\boldsymbol{e}_i
=a_i\boldsymbol{e}_i$$
$$A\boldsymbol{x}=a_{ij}x_j\boldsymbol{e}_i
\hspace{0.05in}\text{for $m\times n$ matrix $A$}$$
$$\delta_{ii}=3$$
$$[\dots]_j\delta_{jk}
=[\dots]_k$$
$$\boldsymbol{e}_i\cdot
\boldsymbol{e}_j=\delta_{ij}$$
$$\boldsymbol{e}_i\times
\boldsymbol{e}_j=
\epsilon_{ijk}\boldsymbol{e}_k$$
$$\boldsymbol{a}\times\boldsymbol{b}
=\epsilon_{ijk}a_j b_k\boldsymbol{e}_i$$
$$\boldsymbol{a}\cdot
(\boldsymbol{b}\times\boldsymbol{c})
=\epsilon_{ijk}a_i b_j c_k$$
$$\epsilon_{ijk}\epsilon_{klm}
=\delta_{il}\delta_{jm}
-\delta_{im}\delta_{jl}$$
$$\epsilon_{ijk}\epsilon_{ijl}
=2\delta_{kl}
\hspace{0.05in}\text{and}\hspace{0.05in}
\epsilon_{ijk}\epsilon_{ijk}=6.$$

\subsubsection*{Transformations}
Let matrix $L$ relate
basis $\{\boldsymbol{e}_i\}$ to basis
$\{\boldsymbol{e}'_i\}$ with rule:
$$\boldsymbol{e}'_i
=\ell_{ij}\boldsymbol{e}_j
\hspace{0.05in}\text{where}\hspace{0.05in}
(L)_{ij}=\ell_{ij}.$$
Then $L^T L=LL^T=I$, and:
$$\ell_{ik}\ell_{jk}
=\ell_{ki}\ell_{kj}=\delta_{ij}$$
$$p'_i=\ell_{ij}p_j
\hspace{0.05in}\text{for}\hspace{0.05in}
\boldsymbol{p}=p_i\boldsymbol{e}_i
=p'_i\boldsymbol{e}'_i.$$

\subsubsection*{Tensors}
A rank $3$ tensor is defined as:
$$T'_{ijk}=\ell_{ip}\ell_{jq}\ell_{kr}T_{pqr}$$
which relates frame $S$ in $\{\boldsymbol{e}_i\}$ to
frame $S'$ in $\{\boldsymbol{e}'_i\}$ with
rule $\boldsymbol{e}'_i=\ell_{ij}\boldsymbol{e}_j$, etc.

Properties of tensors:
\begin{enumerate}
    \item The \underline{addition} of two rank
    $n$ tensors is also a rank $n$ tensor.
    
    \item The \underline{multiplication} of a
    rank $m$ tensor with a rank $n$ tensor yields
    a rank $m+n$ tensor.

    \item If $T_{ijk\dots s}$ is a rank $m$ tensor
    then $T_{\textcolor{red}{ii}k\dots s}$ is a rank $m-2$ tensor.

    \item If $T_{ij}$ is a tensor then
    $T_{ji}$ is also a tensor. Explicitly:
    $$T'_{ij}=\ell_{ip}\ell_{jq}T_{pq}
    \implies T'=LTL^T$$
    $$T'_{\textcolor{red}{ji}}=\ell_{\textcolor{red}{j}p}
    \ell_{\textcolor{red}{i}q}T_{pq}.$$
\end{enumerate}

\subsubsection*{Symmetric tensors}
$T_{ij}$ is a \underline{symmetric} tensor
when $T_{ij}=T_{ji}$ in frame $S$.
Then $T'_{ij}=T'_{ji}$ in frame $S'$.

Similarly $T_{ij}$ is an \underline{anti-symmetric}
tensor if $T_{ij}=-T_{ji}$ and
$T'_{ij}=-T'_{ji}$.

Finally \textcolor{red}{any tensor} can be written as
a sum of symmetric and anti-symmetric parts:
$$T_{ij}=\frac{1}{2}(T_{ij}+T_{ji})
+\frac{1}{2}(T_{ij}-T_{ji}).$$

\subsubsection*{Quotient theorem}
Consider $9$ entities $T_{ij}$ in frame $S$
and $T'_{ij}$ in frame $S'$. Let $b_i=T_{ij}a_j$
where $a_j$ is a vector.
If $b_i$ \underline{always} transforms as a vector
then $T_{ij}$ is a rank $2$ tensor.

Generalising, let $R_{ijk\dots r}$ be a rank $m$
tensor and $T_{ijk\dots s}$ a set of $3^n$ numbers
where $n>m$. If $T_{ijk\dots s}R_{ijk\dots r}$
is a rank $n-m$ tensor then $T_{ijk\dots s}$
is a rank $n$ tensor.

\subsubsection*{Matrices}
We define a $m\times n$ matrix $A$ as $(A)_{ij}=a_{ij}$
where $i=1,\dots,m$ and $j=1,\dots,n$.
\begin{itemize}
    \item $\Trace A=a_{ii}$
    \item $(A^T)_{ij}=a_{ji}$
    \item $(AB)^T=B^T A^T$
    \item $(I)_{ij}=\delta_{ij}$
\end{itemize}
The determinant of a $3\times3$ matrix $A$ is:
\begin{align*}
    \det A
    &=\left|
        \begin{array}{lll}
            a_{11} & a_{12} & a_{13} \\
            a_{21} & a_{22} & a_{23} \\
            a_{31} & a_{32} & a_{33}
        \end{array}
    \right| \\
    &=\epsilon_{lmn}a_{1l}a_{2m}a_{3n} \\
    &=\epsilon_{lmn}a_{l1}a_{m2}a_{n3}.
\end{align*}

Furthermore:
$$\epsilon_{ijk}\det A=
\epsilon_{lmn}a_{il}a_{jm}a_{kn}$$
$$\epsilon_{lmn}\det A=
\epsilon_{ijk}a_{il}a_{jkm}a_{kn}$$
$$\det A=\frac{1}{3!}\epsilon_{ijk}
\epsilon_{lmn}a_{il}a_{jm}a_{kn}.$$

Properties of determinants:
\begin{enumerate}
    \item Adding rows to each other \\
    \underline{does not} change the determinant.
    
    \item Interchanging two rows \\
    \underline{changes determinant signs}.

    \item $\det A=\det A^T$
    
    \item $\det(AB)=\det A\cdot\det B$
\end{enumerate}
These also apply to columns. Finally:
$$\epsilon_{ijk}\epsilon_{lmn}\det A
=\left|
    \begin{array}{lll}
        a_{il} & a_{im} & a_{in} \\
        a_{jl} & a_{jm} & a_{jn} \\
        a_{kl} & a_{km} & a_{kn}
    \end{array}
\right|$$
and setting $A=I$ yields:
$$\epsilon_{ijk}\epsilon_{lmn}
=\left|
    \begin{array}{lll}
        \delta_{il} & \delta_{im} & \delta_{in} \\
        \delta_{jl} & \delta_{jm} & \delta_{jn} \\
        \delta_{kl} & \delta_{km} & \delta_{kn}
    \end{array}
\right|.$$

\subsubsection*{Linear equations}
Let $\boldsymbol{y}=A\boldsymbol{x}$.
Then $x_i=A^{-1}_{ij}y_i$ with:
\begin{align*}
    A^{-1}_{ij}&=\frac{1}{2}\frac{1}{\det A}
    \epsilon_{imn}\epsilon_{jpq}a_{pm}a_{qn} \\
    &=\frac{1}{\det A}C_{ij}^T
\end{align*}
where $C$ is the cofactor matrix of $A$.

\subsubsection*{Pseudotensors}
A rank $2$ pseudotensor is defined as:
$$T'_{ij}=(\det L)\ell_{ip}\ell_{jq}T_{pq}$$
where $(L)_{ij}=\ell_{ij}$
and $\det L=\pm1$.

Pseudovectors are rank $1$ pseudotensors.

\subsubsection*{Invariant tensors}
Tensor $T$ is \underline{invariant} or isotropic if:
$$T_{ijk\dots}=\ell_{i\alpha}\ell_{j\beta}\ell_{k\gamma}
\cdots T_{\alpha\beta\gamma\dots}$$
for every orthogonal matrix $L$.
\begin{itemize}
    \item If $a_{ij}$ is a rank $2$
    invariant tensor then
    $a_{ij}=\lambda\delta_{ij}$.

    \item The most general rank $3$ invariant
    \underline{pseudotensor} is
    $a_{ijk}=\lambda\epsilon_{ijk}$.
    There are \underline{no} rank $3$
    invariant true tensors.

    \item Invariant true tensors can only be
    even ranked.

    \item Invariant pseudotensors can only be
    odd ranked.
\end{itemize}

\newpage

\subsubsection*{Rotation tensors}
The clockwise \underline{rotation} of position vector
$\boldsymbol{x}$ to $\boldsymbol{y}$
about unit vector $\hat{\boldsymbol{n}}$
is given by:
$$y_i=R_{ij}(\theta,\hat{\boldsymbol{n}})x_j$$
\begin{align*}
    R_{ij}(\theta,\hat{\boldsymbol{n}})
    &=\delta_{ij}\cos\theta+(1-\cos\theta)n_i n_j \\
    &\quad-\epsilon_{ijk}n_k\sin\theta
\end{align*}
and is the rotation tensor.

\subsubsection*{Reflections and inversions}
The \underline{reflection} of vector $\boldsymbol{x}$
to $\boldsymbol{y}$ in \\
plane with unit vector $\hat{\boldsymbol{n}}$ is:
$$y_i=\sigma_{ij}x_j$$
$$\sigma_{ij}=\delta_{ij}-2n_i n_j.$$
The \underline{inversion} of vector $\boldsymbol{x}$
to $\boldsymbol{y}$ is given by
$\boldsymbol{y}=-\boldsymbol{x}$
and is defined as:
$$y_i=P_{ij}x_j$$
$$P_{ij}=\delta_{ij}.$$

\subsubsection*{Projections}
We define $P$ to be a \underline{parallel}
projection operator to vector $\boldsymbol{u}$ if:
$$P\boldsymbol{u}=\boldsymbol{u}
\hspace{0.05in}\text{and}\hspace{0.05in}
P\boldsymbol{v}=\boldsymbol{0}$$
where $\boldsymbol{u}\cdot\boldsymbol{v}=\boldsymbol{0}$.
Then:
$$P_{ij}=\frac{u_i u_j}{u^2}.$$
Similarly we define $Q$ to be an \underline{orthogonal} projection
to vector $\boldsymbol{u}$ if:
$$Q\boldsymbol{u}=\boldsymbol{0}
\hspace{0.05in}\text{and}\hspace{0.05in}
Q\boldsymbol{v}=\boldsymbol{v}.$$
Here $Q=I-P$.

\subsubsection*{Inertia tensors}
Let $\boldsymbol{L}$ denote the angular momentum of a
rigid body about the origin of mass $m$,
volume $V$ and density $\rho$
at position $\boldsymbol{r}$
with velocity $\boldsymbol{v}$. Then:
$$L_i=I_{ij}\omega_j$$
$$I_{ij}=I_{ij}(O)=\int_V\rho(r^2\delta_{ij}-x_i x_j)\dd V$$
where $I_{ij}(O)$ is the inertia tensor about
the origin.
The \underline{kinetic energy} of such a body is:
$$T=\frac{1}{2}I_{ij}\omega_i\omega_j
=\frac{1}{2}\boldsymbol{L}\cdot\boldsymbol{\omega}.$$

\subsubsection*{Parallel axis theorem}
Consider the same rigid body now
with centre of mass $G$ and let
$\overrightarrow{OG}=\boldsymbol{R}$. Then:
$$I_{ij}(O)=I_{ij}(G)+M(R^2\delta_{ij}-X_i X_j)$$
$$M=\int_V\rho'(\boldsymbol{r}')\dd V'.$$

\subsubsection*{Diagonalisation}
Let $\vc{L}=I_{ij}\omega_j$
where $I_{ij}$ is a rank $2$ tensor \\
and let $\vc{L}=\lambda\hspace{0.01in}\vc{\omega}$.
Then:
$$(I_{ij}-\lambda\delta_{ij})\hspace{0.01in}\omega_j=0
\implies\det(I_{ij}-\lambda\delta_{ij})=0$$
where expanding this gives:
$$P-Q\lambda+R\lambda^2-\lambda^3=0$$
for $P=\det I$,
$Q=\frac{1}{2}[(\trace I)^2-\trace(I^2)]$
and $R=\trace I$
given \underline{tensor} $I$.

\subsubsection*{Real symmetric tensors}
Let rank $2$ real symmetric tensor $T$
be diagonalisable with real eigenvalues
$\lambda^{(i)}$ and orthonormal eigenvectors
$\vc{\ell}^{(i)}$ where $i=1,2,3$.
Let transformation matrix be:
$$L_{ij}=\ell_j^{(i)}
=\begin{pmatrix}
    \ell_1^{(1)} & \ell_2^{(1)} & \ell_3^{(1)} \\
    \ell_1^{(2)} & \ell_2^{(2)} & \ell_3^{(2)} \\
    \ell_1^{(3)} & \ell_2^{(3)} & \ell_3^{(3)}
\end{pmatrix}_{ij}$$
and always defined such that $\det L=+1$
which transforms frame $S\rightarrow S'$.

Then since $T_{pq}\ell_q^{(i)}=\lambda^{(i)}\ell_p^{(i)}$:
\begin{align*}
    T'_{ij}
    &=\ell_{ip}\ell_{jq}T_{pq} \\
    &=\lambda^{(i)}\delta_{ij}
    =\begin{pmatrix}
        \lambda^{(1)} & 0 & 0 \\
        0 & \lambda^{(2)} & 0 \\
        0 & 0 & \lambda^{(3)}
    \end{pmatrix}_{ij}.
\end{align*}

\subsubsection*{Taylor expansions}
In the one-dimensional case we have:
$$f(x)=\sum_{n=0}^{\infty}
\frac{1}{n!}f^{(n)}(a)(x-a)^n$$
and is $f$ expanded about $x=a$.

Trignometric expansions are in radians!
\begin{align*}
    \therefore f(x+a)
    &=\sum_{n=0}^{\infty}\frac{1}{n!}
    f^{(n)}(x)a^n \\
    &=\exp\left(a\dv{x}\right)f(x)
\end{align*}
Then for three dimensions:
\begin{align*}
    \phi(\boldsymbol{r}+\boldsymbol{a})
    &=\sum_{n=0}^{\infty}\frac{1}{n!}
    (\boldsymbol{a}\cdot\boldsymbol{\nabla}_r)^n
    \phi(\boldsymbol{r}) \\
    &=\exp(\boldsymbol{a}\cdot
    \boldsymbol{\nabla}_r)\phi(\boldsymbol{r}).
\end{align*}

\subsubsection*{Curvilinear coordinates}
Let $x_i$ denote Cartesian coordinates
and $u_i$ denote curvilinear coordinates. Then:
$$(x_1,x_2,x_3)\rightarrow(u_1,u_2,u_3)$$
where each $u_i=u_i(x_1,x_2,x_3)$ and:
\begin{align*}
    \vc{r}
    &=x_1\vc{e}_1+x_2\vc{e}_2+x_3\vc{e}_3 \\
    &=u_1\vc{e}_{u_1}+u_2\vc{e}_{u_2}+u_3\vc{e}_{u_3}.
\end{align*}

\subsubsection*{Scale factors}
Let $u_1\rightarrow u_1+\dd u_1$ in
$\boldsymbol{r}=\boldsymbol{r}(u_1,u_2,u_3)$.
Then $\dd\vc{r}$ in 
$\boldsymbol{r}\rightarrow\boldsymbol{r}+\dd\boldsymbol{r}$
is defined as:
$$\dd\boldsymbol{r}
=\frac{\partial\boldsymbol{r}}{\partial u_1}\dd u_1
\deq h_1\boldsymbol{e}_1\dd u_1.$$
$h_1$ is the scale factor of unit vector 
$\boldsymbol{e}_1$:
$$h_1=\left|\frac{\partial
\boldsymbol{r}}{\partial u_1}\right|
\hspace{0.05in}\text{and}\hspace{0.05in}
\boldsymbol{e}_1=\frac{1}{h_1}
\frac{\partial\boldsymbol{r}}{\partial u_1}.$$
If $\boldsymbol{e}_i\cdot\boldsymbol{e}_j=\delta_{ij}$
then $u_i$ is an \textbf{orthogonal}
curvilinear coordinate system.

\subsubsection*{Vector and arc length}
The \underline{vector length} 
$\dd\vc{r}$ of $\boldsymbol{r}$ 
is defined as:
$$\dd\boldsymbol{r}=
\sum_{i=1}^{3}h_i\dd u_i\boldsymbol{e}_i$$
where
$u_i\rightarrow u_i+\dd u_i$
for $\forall i=1,2,3$.

Then the \underline{arc length}
$\dd s$ is defined as:
\begin{align*}
    (\dd s)^2
    &=\dd\vc{r}\cdot\dd\vc{r} \\
    &=g_{ij}\hspace{0.01in}\dd u_i\dd u_j
\end{align*}
where $g_{ij}$ is the metric tensor:
\begin{align*}
    g_{ij}&=g_{ji}=\frac{\partial x_k}{\partial u_i}
    \frac{\partial x_k}{\partial u_j} \\
    &=h_i h_j(\vc{e}_i\cdot\vc{e}_j).
\end{align*}

\subsubsection*{Area and volume}
Let $\dd\vc{r}_i=h_i\vc{e}_i\dd u_i$ denote
vector length when
$u_i\rightarrow u_i+\dd u_i$.
(\textbf{No} sum!)

The infinitesimal \underline{vector area}
formed by $\dd\vc{r}_1$
and $\dd\vc{r}_2$ is:
$$\dd\vc{S}=(h_1\dd\vc{u}_1\vc{e}_1)
\times(h_2\dd\vc{u}_2\vc{e}_2).$$
Similarly the infinitesimal \underline{volume} 
formed by edges $\dd\vc{r}_1$, $\dd\vc{r}_2$
and $\dd\vc{r}_3$ is:
\begin{align*}
    \dd V&=|(\dd\vc{r}_1\times\dd\vc{r}_2)
    \cdot\dd\vc{r}_3| \\
    &=\sqrt{g}\hspace{0.01in}\dd u_1\dd u_2\dd u_3
\end{align*}
where $g=\det(g_{ij})$.

\subsubsection*{Cylindrical coordinates}
$(u_1,u_2,u_3)=(\rho,\phi,z)$ where $\rho$
represents the radial distance from the origin
and $\phi$ is the anticlockwise rotation angle
on the $x$-$y$ plane. In Cartesian unit vectors:
$$\vc{r}=\rho\cos\phi\vc{e}_1
+\rho\sin\phi\vc{e}_2+z\vc{e}_3$$
$$h_{\rho}=1,
\hspace{0.1in}
\vc{e}_{\rho}=\cos\phi\vc{e}_1+\sin\phi\vc{e}_2$$
$$h_{\phi}=\rho,
\hspace{0.1in}
\vc{e}_{\phi}=-\sin\phi\vc{e}_1+\cos\phi\vc{e}_2$$
$$h_z=1,
\hspace{0.1in}
\vc{e}_{z}=\vc{e}_3$$
and forms an orthogonal basis.

\subsubsection*{Spherical coordinates}
$(u_1,u_2,u_3)=(r,\theta,\phi)$ where
$\theta$ represents the clockwise
rotation angle in $y$-$z$ plane
and $\phi$ the anticlockwise
rotation angle in $x$-$y$ plane.
In Cartesian unit vectors:
$$\vc{r}=r\sin\theta\cos\phi\vc{e}_1
+r\sin\theta\sin\phi\vc{e}_2
+r\cos\theta\vc{e}_3$$
$$h_{r}=1,\hspace{0.05in} h_{\theta}=r,
\hspace{0.05in} h_{\phi}=r\sin\theta$$
$$\vc{e}_{r}=\sin\theta\cos\phi\vc{e}_1
+\sin\theta\sin\phi\vc{e}_2+\cos\theta\vc{e}_3$$
$$\vc{e}_{\theta}=\cos\theta\cos\phi\vc{e}_1
+\cos\theta\sin\phi\vc{e}_2-\sin\theta\vc{e}_3$$
$$\vc{e}_{\phi}=-\sin\phi\vc{e}_1+\cos\phi\vc{e}_2$$
and also forms an orthogonal set.
\begin{center}
    \includegraphics[scale=0.35]{f0.png}
\end{center}

\subsubsection*{Gradient}

\subsubsection*{Divergence}

\subsubsection*{Curl}

\subsubsection*{Laplacian}

\subsubsection*{Stokes' theorem}

\subsubsection*{Divergence theorem}

\subsubsection*{Dirac delta function}

\end{multicols*}

\end{document}